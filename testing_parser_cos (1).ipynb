{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn nltk transformers sentence-transformers pdfminer.six faiss-cpu matplotlib seaborn tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1afDnb66yVfv",
        "outputId": "05c4a3ee-ff5e-43c6-98e8-12decd63a191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250416-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading pdfminer_six-20250416-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m847.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pdfminer.six, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pdfminer.six-20250416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qb6hE4lyOUw",
        "outputId": "b72e90ef-ca16-496e-ffe9-3b1c93304e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 resume embeddings and 19824 job embeddings\n",
            "Loaded test dataset with 10 resume-job title pairs\n",
            "Evaluating resume-job matching using cosine similarity...\n",
            "\n",
            "Actual resume filenames in embeddings:\n",
            "1. nlp_1.pdf\n",
            "2. nlp_2.pdf\n",
            "3. nlp_3.pdf\n",
            "4. nlp_4.pdf\n",
            "5. nlp_5.pdf\n",
            "6. nlp_6.pdf\n",
            "7. nlp_7.pdf\n",
            "8. nlp_8.pdf\n",
            "9. nlp_9.pdf\n",
            "10. nlp_10.pdf\n",
            "\n",
            "Proposed mapping from test names to actual filenames:\n",
            "nlp_1 → nlp_1.pdf\n",
            "nlp_2 → nlp_2.pdf\n",
            "nlp_3 → nlp_3.pdf\n",
            "nlp_4 → nlp_4.pdf\n",
            "nlp_5 → nlp_5.pdf\n",
            "nlp_6 → nlp_6.pdf\n",
            "nlp_7 → nlp_7.pdf\n",
            "nlp_8 → nlp_8.pdf\n",
            "nlp_9 → nlp_9.pdf\n",
            "nlp_10 → nlp_10.pdf\n",
            "\n",
            "Is this mapping correct? (y/n)\n",
            "y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating resume-job matches (cosine): 100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating test report...\n",
            "Generated test report at test_results_cosine/test_report_cos.md\n",
            "\n",
            "Test Results (Cosine Similarity):\n",
            "Top-1 Accuracy: 10.00% (1/10)\n",
            "Top-5 Accuracy: 50.00% (5/10)\n",
            "Top-10 Accuracy: 60.00% (6/10)\n",
            "\n",
            "Execution completed in 7.97 seconds\n",
            "Results saved to test_results_cosine directory\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def load_embeddings(resume_file=\"resume_embeddings.pkl\", job_file=\"job_embeddings.pkl\"):\n",
        "    \"\"\"Load precomputed embeddings from files.\"\"\"\n",
        "    # Check if files exist\n",
        "    if not os.path.exists(resume_file):\n",
        "        print(f\"Error: Resume embeddings file {resume_file} not found.\")\n",
        "        return None, None\n",
        "\n",
        "    if not os.path.exists(job_file):\n",
        "        print(f\"Error: Job embeddings file {job_file} not found.\")\n",
        "        return None, None\n",
        "\n",
        "    # Load resume embeddings\n",
        "    with open(resume_file, 'rb') as f:\n",
        "        resume_data = pickle.load(f)\n",
        "\n",
        "    # Load job embeddings\n",
        "    with open(job_file, 'rb') as f:\n",
        "        job_data = pickle.load(f)\n",
        "\n",
        "    print(f\"Loaded {len(resume_data)} resume embeddings and {len(job_data)} job embeddings\")\n",
        "    return resume_data, job_data\n",
        "\n",
        "def load_test_dataset(test_file=\"test_dataset.xlsx\"):\n",
        "    \"\"\"Load test dataset with known correct job titles for each resume.\"\"\"\n",
        "    if not os.path.exists(test_file):\n",
        "        print(f\"Test dataset file {test_file} not found.\")\n",
        "        return None\n",
        "\n",
        "    test_data = pd.read_excel(test_file)\n",
        "    print(f\"Loaded test dataset with {len(test_data)} resume-job title pairs\")\n",
        "    return test_data\n",
        "\n",
        "def match_resume_to_jobs_cosine(resume_embedding, job_data, k=10):\n",
        "    \"\"\"Match a resume to jobs using cosine similarity.\"\"\"\n",
        "    # Reshape resume embedding for sklearn cosine_similarity\n",
        "    query_vector = resume_embedding.reshape(1, -1)\n",
        "\n",
        "    # Extract all job embeddings\n",
        "    job_embeddings = np.array([job[\"embedding\"] for job in job_data])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = cosine_similarity(query_vector, job_embeddings)[0]\n",
        "\n",
        "    # Get indices of top k matches\n",
        "    top_indices = np.argsort(similarities)[::-1][:k]\n",
        "\n",
        "    # Get the matching jobs\n",
        "    matches = []\n",
        "    for i, idx in enumerate(top_indices):\n",
        "        job = job_data[idx]\n",
        "        matches.append({\n",
        "            \"job_id\": job[\"job_id\"],\n",
        "            \"job_title\": job[\"job_title\"],\n",
        "            \"similarity_score\": similarities[idx],  # Cosine similarity score\n",
        "            \"experience_level\": job.get(\"formatted_experience_level\", \"\"),\n",
        "            \"location\": job.get(\"location\", \"\"),\n",
        "            \"remote_allowed\": job.get(\"remote_allowed\", False),\n",
        "            \"work_type\": job.get(\"work_type\", \"\")\n",
        "        })\n",
        "\n",
        "    return matches\n",
        "\n",
        "def print_resume_filenames(resume_data):\n",
        "    \"\"\"Print the actual filenames in the resume embeddings to help with debugging.\"\"\"\n",
        "    print(\"\\nActual resume filenames in embeddings:\")\n",
        "    for i, resume in enumerate(resume_data):\n",
        "        print(f\"{i+1}. {resume.get('filename', 'No filename found')}\")\n",
        "\n",
        "def map_test_names_to_actual_names(resume_data, test_data):\n",
        "    \"\"\"Create a mapping from test dataset names to actual resume filenames.\"\"\"\n",
        "    # First, print the filenames to help with debugging\n",
        "    print_resume_filenames(resume_data)\n",
        "\n",
        "    # Extract all filenames from resume data\n",
        "    all_filenames = [resume.get('filename', '') for resume in resume_data]\n",
        "\n",
        "    # Try to create a mapping based on position (assuming the order matches)\n",
        "    # This is just a fallback approach\n",
        "    test_names = test_data['Resume_title'].tolist()\n",
        "    position_mapping = {}\n",
        "\n",
        "    for i, test_name in enumerate(test_names):\n",
        "        if i < len(all_filenames):\n",
        "            position_mapping[test_name] = all_filenames[i]\n",
        "\n",
        "    print(\"\\nProposed mapping from test names to actual filenames:\")\n",
        "    for test_name, actual_name in position_mapping.items():\n",
        "        print(f\"{test_name} → {actual_name}\")\n",
        "\n",
        "    # Ask user to confirm or modify the mapping\n",
        "    print(\"\\nIs this mapping correct? (y/n)\")\n",
        "    response = input().strip().lower()\n",
        "\n",
        "    if response == 'y':\n",
        "        return position_mapping\n",
        "\n",
        "    # If not correct, allow manual mapping\n",
        "    print(\"\\nPlease enter the correct mapping in format 'test_name:actual_filename' (one per line)\")\n",
        "    print(\"Press Enter twice when done\")\n",
        "    manual_mapping = {}\n",
        "\n",
        "    while True:\n",
        "        line = input().strip()\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        if ':' in line:\n",
        "            test_name, actual_name = line.split(':', 1)\n",
        "            manual_mapping[test_name.strip()] = actual_name.strip()\n",
        "\n",
        "    return manual_mapping if manual_mapping else position_mapping\n",
        "\n",
        "def evaluate_job_title_matches_cosine(resume_data, job_data, test_data, output_dir=\"test_results_cosine\"):\n",
        "    \"\"\"Evaluate how well the system matches resumes to the correct job titles using cosine similarity.\"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Create a mapping from test dataset names to actual resume filenames\n",
        "    filename_mapping = map_test_names_to_actual_names(resume_data, test_data)\n",
        "\n",
        "    # Convert test_data to a dictionary for easier lookup\n",
        "    test_dict = dict(zip(test_data['Resume_title'], test_data['Job Title']))\n",
        "\n",
        "    # Create a dictionary to store results\n",
        "    results = {\n",
        "        \"top_1\": 0,\n",
        "        \"top_5\": 0,\n",
        "        \"top_10\": 0,\n",
        "        \"total_tested\": 0,\n",
        "        \"detailed_results\": []\n",
        "    }\n",
        "\n",
        "    # Create a dictionary for resume lookup by filename\n",
        "    resume_dict = {resume[\"filename\"]: resume for resume in resume_data}\n",
        "\n",
        "    # Process each resume in the test dataset\n",
        "    for test_resume_title, expected_job_title in tqdm(test_dict.items(), desc=\"Evaluating resume-job matches (cosine)\"):\n",
        "        # Get the actual filename from the mapping\n",
        "        actual_filename = filename_mapping.get(test_resume_title)\n",
        "\n",
        "        if not actual_filename:\n",
        "            print(f\"Warning: No mapping found for {test_resume_title}\")\n",
        "            continue\n",
        "\n",
        "        # Find the resume in our data\n",
        "        resume = resume_dict.get(actual_filename)\n",
        "        if not resume:\n",
        "            print(f\"Warning: Resume {actual_filename} not found in embeddings\")\n",
        "            continue\n",
        "\n",
        "        # Match resume to jobs using cosine similarity\n",
        "        matches = match_resume_to_jobs_cosine(resume[\"full_embedding\"], job_data, k=10)\n",
        "\n",
        "        # If no matches found, continue to next resume\n",
        "        if not matches:\n",
        "            print(f\"Warning: No job matches found for resume {test_resume_title}\")\n",
        "            continue\n",
        "\n",
        "        # Extract job titles\n",
        "        matched_job_titles = [match[\"job_title\"] for match in matches]\n",
        "\n",
        "        # Check if the expected job title is in the top matches\n",
        "        # Note: We'll do a partial match to account for variations in title naming\n",
        "        in_top_1 = any(expected_job_title.lower() in title.lower() for title in [matched_job_titles[0]])\n",
        "        in_top_5 = any(expected_job_title.lower() in title.lower() for title in matched_job_titles[:5])\n",
        "        in_top_10 = any(expected_job_title.lower() in title.lower() for title in matched_job_titles[:10])\n",
        "\n",
        "        # Update counts\n",
        "        results[\"total_tested\"] += 1\n",
        "        if in_top_1:\n",
        "            results[\"top_1\"] += 1\n",
        "        if in_top_5:\n",
        "            results[\"top_5\"] += 1\n",
        "        if in_top_10:\n",
        "            results[\"top_10\"] += 1\n",
        "\n",
        "        # Store detailed results for this resume\n",
        "        results[\"detailed_results\"].append({\n",
        "            \"resume_title\": test_resume_title,\n",
        "            \"actual_filename\": actual_filename,\n",
        "            \"expected_job_title\": expected_job_title,\n",
        "            \"top_match\": matched_job_titles[0],\n",
        "            \"in_top_1\": in_top_1,\n",
        "            \"in_top_5\": in_top_5,\n",
        "            \"in_top_10\": in_top_10,\n",
        "            \"similarity_score\": matches[0][\"similarity_score\"],\n",
        "            \"all_matches\": matched_job_titles[:10]\n",
        "        })\n",
        "\n",
        "        # Create visualization for this match\n",
        "        visualize_match(test_resume_title, expected_job_title, matches[:10], output_dir)\n",
        "\n",
        "    # Calculate accuracies\n",
        "    if results[\"total_tested\"] > 0:\n",
        "        results[\"top_1_accuracy\"] = results[\"top_1\"] / results[\"total_tested\"]\n",
        "        results[\"top_5_accuracy\"] = results[\"top_5\"] / results[\"total_tested\"]\n",
        "        results[\"top_10_accuracy\"] = results[\"top_10\"] / results[\"total_tested\"]\n",
        "    else:\n",
        "        results[\"top_1_accuracy\"] = 0\n",
        "        results[\"top_5_accuracy\"] = 0\n",
        "        results[\"top_10_accuracy\"] = 0\n",
        "\n",
        "    # Save detailed results to CSV\n",
        "    detailed_df = pd.DataFrame(results[\"detailed_results\"])\n",
        "    detailed_df.to_csv(os.path.join(output_dir, \"detailed_results.csv\"), index=False)\n",
        "\n",
        "    # Create summary visualization\n",
        "    visualize_accuracy(results, output_dir)\n",
        "\n",
        "    # Create a confusion matrix\n",
        "    create_confusion_matrix(results[\"detailed_results\"], output_dir)\n",
        "\n",
        "    return results\n",
        "\n",
        "def visualize_match(resume_title, expected_job_title, matches, output_dir):\n",
        "    \"\"\"Create visualization for a single resume match.\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Extract job titles and scores\n",
        "    job_titles = [match['job_title'][:30] + '...' if len(match['job_title']) > 30 else match['job_title']\n",
        "                 for match in matches]\n",
        "    scores = [match['similarity_score'] for match in matches]\n",
        "\n",
        "    # Highlight the expected job title if it's in the matches\n",
        "    colors = ['#3498db' for _ in range(len(job_titles))]\n",
        "    for i, title in enumerate(job_titles):\n",
        "        if expected_job_title.lower() in title.lower():\n",
        "            colors[i] = '#2ecc71'  # Green for correct matches\n",
        "\n",
        "    # Create horizontal bar chart\n",
        "    bars = plt.barh(range(len(job_titles)), scores, color=colors)\n",
        "    plt.yticks(range(len(job_titles)), job_titles)\n",
        "    plt.title(f\"Job Matches for {resume_title} (Cosine Similarity)\\nExpected: {expected_job_title}\")\n",
        "    plt.xlabel('Similarity Score')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Add score labels\n",
        "    for i, bar in enumerate(bars):\n",
        "        plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                f'{scores[i]:.3f}', va='center')\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(os.path.join(output_dir, f\"match_{resume_title}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def visualize_accuracy(results, output_dir):\n",
        "    \"\"\"Create visualization for overall accuracy results.\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    metrics = [\"Top-1\", \"Top-5\", \"Top-10\"]\n",
        "    values = [results[\"top_1_accuracy\"], results[\"top_5_accuracy\"], results[\"top_10_accuracy\"]]\n",
        "\n",
        "    bars = plt.bar(metrics, values, color=['#3498db', '#2ecc71', '#f39c12'])\n",
        "\n",
        "    plt.title(\"Resume-Job Matching Accuracy (Cosine Similarity)\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.ylim(0, 1.0)\n",
        "\n",
        "    # Add percentage labels\n",
        "    for i, v in enumerate(values):\n",
        "        plt.text(i, v + 0.01, f\"{v:.1%}\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"accuracy_metrics_cos.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Create text summary\n",
        "    with open(os.path.join(output_dir, \"accuracy_summary_cos.txt\"), 'w') as f:\n",
        "        f.write(\"Resume-Job Matching Accuracy Summary (Cosine Similarity)\\n\")\n",
        "        f.write(\"==================================================\\n\\n\")\n",
        "        f.write(f\"Total resumes tested: {results['total_tested']}\\n\\n\")\n",
        "        f.write(f\"Top-1 Accuracy: {results['top_1_accuracy']:.2%} ({results['top_1']}/{results['total_tested']})\\n\")\n",
        "        f.write(f\"Top-5 Accuracy: {results['top_5_accuracy']:.2%} ({results['top_5']}/{results['total_tested']})\\n\")\n",
        "        f.write(f\"Top-10 Accuracy: {results['top_10_accuracy']:.2%} ({results['top_10']}/{results['total_tested']})\\n\")\n",
        "\n",
        "def create_confusion_matrix(detailed_results, output_dir):\n",
        "    \"\"\"Create a confusion matrix of expected vs. actual top-1 job titles.\"\"\"\n",
        "    # Check if we have results\n",
        "    if not detailed_results:\n",
        "        print(\"No detailed results to create confusion matrix\")\n",
        "        return\n",
        "\n",
        "    # Extract expected and actual job titles\n",
        "    y_true = [result[\"expected_job_title\"] for result in detailed_results]\n",
        "    y_pred = [result[\"top_match\"] for result in detailed_results]\n",
        "\n",
        "    # Get unique job titles\n",
        "    all_titles = sorted(list(set(y_true + y_pred)))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = np.zeros((len(all_titles), len(all_titles)))\n",
        "    for i, true_title in enumerate(all_titles):\n",
        "        for j, pred_title in enumerate(all_titles):\n",
        "            for result in detailed_results:\n",
        "                if (result[\"expected_job_title\"] == true_title and\n",
        "                    result[\"top_match\"] == pred_title):\n",
        "                    cm[i, j] += 1\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    # Using .0f format for float values\n",
        "    sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"Blues\",\n",
        "                xticklabels=all_titles, yticklabels=all_titles)\n",
        "    plt.title(\"Confusion Matrix: Expected vs. Actual Job Titles (Cosine Similarity)\")\n",
        "    plt.ylabel(\"Expected Job Title\")\n",
        "    plt.xlabel(\"Actual Job Title (Top Match)\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"confusion_matrix_cos.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def generate_test_report(results, output_dir=\"test_results_cosine\"):\n",
        "    \"\"\"Generate a comprehensive test report.\"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Check if we have results\n",
        "    if not results[\"detailed_results\"]:\n",
        "        print(\"No detailed results to generate report\")\n",
        "        return\n",
        "\n",
        "    # Create detailed report in markdown format\n",
        "    with open(os.path.join(output_dir, \"test_report_cos.md\"), 'w') as f:\n",
        "        f.write(\"# Resume-Job Matcher Test Report (Cosine Similarity)\\n\\n\")\n",
        "\n",
        "        f.write(\"## Summary\\n\\n\")\n",
        "        f.write(f\"Total resumes tested: {results['total_tested']}\\n\\n\")\n",
        "        f.write(\"| Metric | Score | Count |\\n\")\n",
        "        f.write(\"|--------|-------|-------|\\n\")\n",
        "        f.write(f\"| Top-1 Accuracy | {results['top_1_accuracy']:.2%} | {results['top_1']}/{results['total_tested']} |\\n\")\n",
        "        f.write(f\"| Top-5 Accuracy | {results['top_5_accuracy']:.2%} | {results['top_5']}/{results['total_tested']} |\\n\")\n",
        "        f.write(f\"| Top-10 Accuracy | {results['top_10_accuracy']:.2%} | {results['top_10']}/{results['total_tested']} |\\n\\n\")\n",
        "\n",
        "        f.write(\"## Detailed Results\\n\\n\")\n",
        "        f.write(\"| Resume | Expected Job Title | Top Match | In Top-1 | In Top-5 | In Top-10 |\\n\")\n",
        "        f.write(\"|--------|-------------------|-----------|----------|----------|----------|\\n\")\n",
        "\n",
        "        for result in results[\"detailed_results\"]:\n",
        "            f.write(f\"| {result['resume_title']} | {result['expected_job_title']} | {result['top_match']} | \")\n",
        "            f.write(f\"{'✓' if result['in_top_1'] else '✗'} | {'✓' if result['in_top_5'] else '✗'} | {'✓' if result['in_top_10'] else '✗'} |\\n\")\n",
        "\n",
        "        f.write(\"\\n## Analysis\\n\\n\")\n",
        "\n",
        "        # Calculate success rate by resume type\n",
        "        resume_types = {}\n",
        "        for result in results[\"detailed_results\"]:\n",
        "            if result[\"expected_job_title\"] not in resume_types:\n",
        "                resume_types[result[\"expected_job_title\"]] = {\"total\": 0, \"correct\": 0}\n",
        "\n",
        "            resume_types[result[\"expected_job_title\"]][\"total\"] += 1\n",
        "            if result[\"in_top_1\"]:\n",
        "                resume_types[result[\"expected_job_title\"]][\"correct\"] += 1\n",
        "\n",
        "        f.write(\"### Success Rate by Expected Job Title\\n\\n\")\n",
        "        f.write(\"| Job Title | Success Rate |\\n\")\n",
        "        f.write(\"|-----------|-------------|\\n\")\n",
        "\n",
        "        for job_title, stats in resume_types.items():\n",
        "            success_rate = stats[\"correct\"] / stats[\"total\"] if stats[\"total\"] > 0 else 0\n",
        "            f.write(f\"| {job_title} | {success_rate:.2%} ({stats['correct']}/{stats['total']}) |\\n\")\n",
        "\n",
        "        f.write(\"\\n### Visualization\\n\\n\")\n",
        "        f.write(\"See the following files in the test_results_cosine directory:\\n\\n\")\n",
        "        f.write(\"- accuracy_metrics.png: Bar chart showing Top-1, Top-5, and Top-10 accuracy\\n\")\n",
        "        f.write(\"- confusion_matrix.png: Heatmap showing expected vs. actual job titles\\n\")\n",
        "        f.write(\"- match_*.png: Individual visualizations for each resume match\\n\")\n",
        "\n",
        "        f.write(\"\\n## Mapping Information\\n\\n\")\n",
        "        f.write(\"| Test Name | Actual Filename |\\n\")\n",
        "        f.write(\"|-----------|----------------|\\n\")\n",
        "\n",
        "        for result in results[\"detailed_results\"]:\n",
        "            f.write(f\"| {result['resume_title']} | {result['actual_filename']} |\\n\")\n",
        "\n",
        "    print(f\"Generated test report at {os.path.join(output_dir, 'test_report_cos.md')}\")\n",
        "\n",
        "def main():\n",
        "    # Start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Set up output directory\n",
        "    output_dir = \"test_results_cosine\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load embeddings\n",
        "    resume_data, job_data = load_embeddings()\n",
        "    if resume_data is None or job_data is None:\n",
        "        return\n",
        "\n",
        "    # Load test dataset\n",
        "    test_data = load_test_dataset()\n",
        "    if test_data is None:\n",
        "        print(\"Cannot run evaluation without test dataset.\")\n",
        "        return\n",
        "\n",
        "    # Run evaluation using cosine similarity\n",
        "    print(\"Evaluating resume-job matching using cosine similarity...\")\n",
        "    results = evaluate_job_title_matches_cosine(resume_data, job_data, test_data, output_dir)\n",
        "\n",
        "    # Generate test report\n",
        "    print(\"Generating test report...\")\n",
        "    generate_test_report(results, output_dir)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nTest Results (Cosine Similarity):\")\n",
        "    print(f\"Top-1 Accuracy: {results['top_1_accuracy']:.2%} ({results['top_1']}/{results['total_tested']})\")\n",
        "    print(f\"Top-5 Accuracy: {results['top_5_accuracy']:.2%} ({results['top_5']}/{results['total_tested']})\")\n",
        "    print(f\"Top-10 Accuracy: {results['top_10_accuracy']:.2%} ({results['top_10']}/{results['total_tested']})\")\n",
        "\n",
        "    # Calculate and print execution time\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    print(f\"\\nExecution completed in {execution_time:.2f} seconds\")\n",
        "    print(f\"Results saved to {output_dir} directory\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}